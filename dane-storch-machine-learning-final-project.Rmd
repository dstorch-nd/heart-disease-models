---
title: "Dane Storch Machine Learning Final Project"
output: html_notebook
---

Final Project - Dane Storch


Install Packages and Import Libraries
```{r}
install.packages("ggplot2")
install.packages("reshape")
install.packages("glmnet")
install.packages("plotmo")
install.packages("randomForest")
install.packages("caret")
install.packages("xgboost")
install.packages("SHAPforxgboost")
install.packages("splitstackshape")
install.packages("fastDummies")
install_github("AppliedDataSciencePartners/xgboostExplainer")
install.packages("devtools")

library(devtools)
library(ggplot2)
library(reshape)
library(glmnet)
library(plotmo)
library(randomForest)
library(caret)
library(xgboost)
library(pROC)
library(SHAPforxgboost)
library(data.table)
library(dplyr)
library(splitstackshape)
library(fastDummies)
library(xgboostExplainer)
```

Load data
```{r}
data <- read.csv('heart_2022_no_nans.csv')
head(data)
```

Clean Data
```{r}
# create response variable
data$HeartDisease <- ifelse(rowSums(data[, c("HadHeartAttack", "HadAngina", "HadStroke")] == "Yes") > 0, 1, 0)

# remove state column and the three heart disease columns that have been consolidated into our response variable
data <- data[, -c(which(colnames(data) %in% c("State", "HadHeartAttack", "HadAngina", "HadStroke")))]

# data is currently in character, change to as.factor
data[sapply(data, is.character)] <- lapply(data[sapply(data, is.character)], as.factor)
data$HeartDisease <- as.factor(data$HeartDisease)

# check na's, dimension, and summary
colSums(is.na(data))
dim(data)
summary(data)
```

Balance the Data Using Under-Sampling
```{r}
# set seed
set.seed(12345)

# split data into response variable classes
majority_class <- filter(data, HeartDisease == 0)
minority_class <- filter(data, HeartDisease == 1)

# use all minority class rows and a random sample n of majority class rows
majority_class_sampled <- sample_n(majority_class, nrow(minority_class))
balanced_data <- bind_rows(majority_class_sampled, minority_class)

# view table to see how many rows there are per class of the new and old data
table(data$HeartDisease)
table(balanced_data$HeartDisease)
```

Split Data using Stratified Sampling
```{r}
# split balanced data for logistic regression and random forest

# set seed
set.seed(12345)

# using response-balanced response data, apply stratified sampling to the as.factor columns that have a large split we should capture
balanced_split_data <- stratified(balanced_data, group = c("HeartDisease", "SmokerStatus", "ECigaretteUsage", "HighRiskLastYear", "PhysicalActivities"), size = 0.2, bothSets = TRUE)
balanced_train_data <- balanced_split_data[[2]]
balanced_test_data <- balanced_split_data[[1]]
nrow(balanced_train_data)
nrow(balanced_test_data)

# set seed
set.seed(12345)

# do the same for the response-unbalanced data in order to use for XGBoost
split_data <- stratified(data, group = c("HeartDisease", "SmokerStatus", "ECigaretteUsage", "HighRiskLastYear", "PhysicalActivities"), size = 0.2, bothSets = TRUE)
unbalanced_train_data <- split_data[[2]]
unbalanced_test_data <- split_data[[1]]
nrow(unbalanced_train_data)
nrow(unbalanced_test_data)
```

Logistic Regression Models
```{r}
# fit logistic regression model using all explanatory variables
glm_all <- glm(HeartDisease ~ ., data = balanced_train_data, family = binomial(link = 'logit'))
summary(glm_all)
```

Logistic Regression Prediction
```{r}
# gather predictive probabilities using the test data
glm_all_probs <- predict(glm_all, newdata = balanced_test_data, type = "response")

# convert probabilities to binary predictions using a 0.5 threshold
glm_all_preds <- ifelse(glm_all_probs > 0.5, 1, 0)

# load the actuals for comparison
glm_all_actuals <- balanced_test_data$HeartDisease

# generate the confusion matrix
confusionMatrix(as.factor(glm_all_preds), as.factor(glm_all_actuals), positive = "1")
```

Fit Lasso Regression Model
```{r}
# scale training data
# scale numeric columns, then cbind the as.factor columns
x_data <- as.data.frame(scale(balanced_train_data[, c(3, 4, 7, 27, 28, 29)]))
x_data <- cbind(x_data, balanced_train_data[, -c(3, 4, 7, 27, 28, 29)])

# scale testing data
# scale numeric columns, then cbind the as.factor columns
x_data_test <- as.data.frame(scale(balanced_test_data[, c(3, 4, 7, 27, 28, 29)]))
x_data_test <- cbind(x_data_test, balanced_test_data[, -c(3, 4, 7, 27, 28, 29)])

# set the explanatory variables from scaled train data
x_vars <- model.matrix(HeartDisease ~., x_data)[,-1]

# fit lasso model
lasso1 <- glmnet(x = x_vars,
                    y = balanced_train_data$HeartDisease,
                    alpha = 1,
                    family = "binomial")
plot_glmnet(lasso1, xvar = "lambda")
```

Lasso Model Lambda Tuning
```{r}
# set seed
set.seed(12345)

# set vector of possible lambda values to test
lambda_seq <- 10^seq(4, -4, by = -.1)

# fit cross validation for lasso model testing for different lambda values
cv.lasso <- cv.glmnet(x = x_vars,
                 y = balanced_train_data$HeartDisease,
                 alpha = 1,
                 family = "binomial",
                 lambda = lambda_seq,
                 nfolds = 10)

# identify and print best lambda value
best_lam <- cv.lasso$lambda.1se
best_lam
```

Fit Final Lasso Model
```{r}
# fit final lasso model using the best lambda
lasso_final <- glmnet(x = x_vars,
                    y = balanced_train_data$HeartDisease,
                    alpha = 1,
                    family = "binomial",
                    lambda = best_lam)
```

Evaluate Final Lasso Model
```{r}
# set test response variable
x_test_vars <- model.matrix(HeartDisease ~ ., x_data_test)[, -1]

# calculate predicted probabilities
predicted_probabilities_lasso <- predict(lasso_final, newx = x_test_vars, type = "response", s = best_lam)

# convert probabilities to binary predictions using a threshold (e.g., 0.5)
predicted_classes_lasso <- ifelse(predicted_probabilities_lasso > 0.5, 1, 0)

# set actuals from balanced test data
actual_classes_lasso <- balanced_test_data$HeartDisease

# generate the confusion matrix
confusionMatrix(as.factor(predicted_classes_lasso), as.factor(actual_classes_lasso), positive = "1")
```

Compare Coefficients from Logistic and Lasso Models
```{r}
# join coefficients from the two models into one data frame and compare
temp <- cbind.data.frame(coef(glm_all), as.vector(coef(lasso_final)))
names(temp) <- c("logisitic Regression", "Logistic Lasso")
rownames(temp) <- names(coef(glm_all))
temp
```

Random Forest Model
```{r}
#fit first random forest model using the balanced training data
rf1 <- randomForest(HeartDisease ~.,
                       data = balanced_train_data,
                       ntree = 1000)
# view model
rf1

# extract oob error, create plot data, and name plot data
oob_error <- rf1$err.rate[,1]
plot_dat <- cbind.data.frame(rep(1:length(oob_error)), oob_error)
names(plot_dat) <- c("trees", "oob_error")


# plot oob error
oob_plot <- ggplot(plot_dat, aes(x = trees, y = oob_error)) +
  geom_point(alpha = 0.5, color = "blue") +
  theme_bw() +
  geom_smooth() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank()) +
  labs(x = "Number of Trees", title = "Error Rate v Number of Trees",
       y = "Error Rate")
oob_plot
```

Random Forest Model Hyperparameter Tuning for Mtry and Node Size
```{r}
# set possible values for mtry and node size
mtry_vals <- c(2, 4, 5, 7, 9, 12, 15, 20, 25)
nodesize_vals <- c(1, 5, 10, 15, 50, 100, 150, 200, 500, 1000)

# create grid for each mtry and node size combination, set initial values as NA to load the grid and store values later
params <- expand.grid(mtry_vals, nodesize_vals)
names(params) <- c("mtry", "nodesize")
acc_vec <- rep(NA, nrow(params))
sens_vec <- rep(NA, nrow(params))

# create for loop, loop through each mtry and node size combination
for(i in 1:nrow(params)){
  rf2 <- randomForest(HeartDisease ~.,
                         data = balanced_train_data,
                         ntree = 150,
                         nodesize = params$nodesize[i],
                         mtry = params$mtry[i])
  # predictions for bagging model
  rf2_preds <-rf2$predicted

  t <- table(rf2_preds, balanced_train_data$HeartDisease)
  c <- confusionMatrix(t, positive = "1")
  
  # store the accuracy and sensitivity for each combination
  acc_vec[i] <- c$overall[1]
  sens_vec[i] <- c$byClass[1]
}
```

View Mtry and Node Size Combinations for Maximizing Accuracy and Sensitivity
```{r}
# data for the parameters along with their calculated accuracy and sensitivity
res_db <- cbind.data.frame(params, acc_vec, sens_vec)

# convert to factor for plotting
res_db$mtry <- as.factor(res_db$mtry)
res_db$nodesize <- as.factor(res_db$nodesize)

# plot accuracy heatmap for mtry and node size
acc_plt_rf <- ggplot(res_db, aes(y = mtry, x = nodesize, fill = acc_vec)) +
  geom_tile() +
  theme_bw() +
  scale_fill_gradient2(low = "blue",
    mid = "white",
    high = "red",
    midpoint =mean(res_db$acc_vec),
    space = "Lab", 
    na.value ="grey",
    guide = "colourbar",
    aesthetics = "fill") +
  labs(x = "Node Size", y = "mtry", fill = "OOB Accuracy")
acc_plt_rf

# plot sensitivity heatmap for mtry and node size
sens_plt_rf <- ggplot(res_db, aes(y = mtry, x = nodesize, fill = sens_vec)) +
  geom_tile() +
  theme_bw() +
  scale_fill_gradient2(low = "blue",
    mid = "white",
    high = "red",
    midpoint =mean(res_db$sens_vec),
    space = "Lab", 
    na.value ="grey",
    guide = "colourbar",
    aesthetics = "fill") +
  labs(x = "Node Size", y = "Mtry", fill = "OOB Sensitivity")
sens_plt_rf
```

Final Random Forest Model with Tuned Mtry and Node Size
```{r}
# fit final model using mtry = 4 and nodesize = 500
rf_final <- randomForest(HeartDisease ~.,
                         data = balanced_train_data,
                         ntree = 150,
                         nodesize = 500,
                         mtry = 4)

# calculate probabilities, predictions, and compare to actuals in confusion matrix
rf_final_preds <- predict(rf_final, balanced_test_data, type = "prob")
rf_pred_class <- rep("0", nrow(rf_final_preds))
rf_pred_class[rf_final_preds[, 2] >= 0.2] <- "1"
t <- table(rf_pred_class, balanced_test_data$HeartDisease)
confusionMatrix(t, positive = "1")
```

XGBoost Model, Data Preparation
```{r}
# we are using the unbalanced data this time, so we need to prep it
# we need numeric data for XGBoost, so we encode our as.factor data into numeric by using binary dummy variables
# convert train and test data into dummy variables
encoded_train_data <- dummy_cols(unbalanced_train_data, remove_first_dummy = FALSE, remove_selected_columns = TRUE)
encoded_test_data <- dummy_cols(unbalanced_test_data, remove_first_dummy = FALSE, remove_selected_columns = TRUE)

# our response variable was split into two columns, so we remove one and rename the other back to its original name
encoded_train_data <- encoded_train_data[, -"HeartDisease_0"]
names(encoded_train_data)[names(encoded_train_data) == "HeartDisease_1"] <- "HeartDisease"

# our response variable was split into two columns, so we remove one and rename the other back to its original name again
encoded_test_data <- encoded_test_data[, -"HeartDisease_0"]
names(encoded_test_data)[names(encoded_test_data) == "HeartDisease_1"] <- "HeartDisease"

# make dtrain and dtest matrix using new encoded unbalanced data
dtrain <- xgb.DMatrix(data = as.matrix(encoded_train_data[, 1:36]), label = as.numeric(encoded_train_data$HeartDisease))
dtest <- xgb.DMatrix(data = as.matrix(encoded_test_data[, 1:36]), label = as.numeric(encoded_test_data$HeartDisease))
```

Fit and Evaluate the First XGBoost Model
```{r}
# set seed
set.seed(12345)

# fit model
boost1 <- xgboost(data = dtrain,
               nrounds = 100,
               verbose = 1,
               print_every_n = 20,
               objective = "binary:logistic",
               eval_metric = "auc",
               eval_metric = "error")

# create predictions and compare to actuals in a confusion matrix
boost1_preds <- predict(boost1, dtest)
pred_dat <- cbind.data.frame(boost1_preds , unbalanced_test_data$HeartDisease)
boost_pred_class <- rep(0, length(boost1_preds))
boost_pred_class[boost1_preds >= 0.5] <- 1
t <- table(boost_pred_class, unbalanced_test_data$HeartDisease)
confusionMatrix(t, positive = "1")
```

Check Best number of Rounds Needed
```{r}
set.seed(12345)
boost_nrounds <- xgb.cv(data = dtrain,
               nfold = 5,
               eta = 0.1,
               nrounds = 1000,
               early_stopping_rounds = 50,
               verbose = 1,
               nthread = 1,
               print_every_n = 20,
               objective = "binary:logistic",
               eval_metric = "auc",
               eval_metric = "error")
```

Hyperparameter Tune for Max Depth and Min Child Weight Values
```{r}
# decide possible values for each hyperparameter
# values are problem-specific
max_depth_vals <- c(3, 5, 7, 10, 15)
min_child_weight <- c(30, 40, 50, 75, 85, 100)

# expand grid of parameter values
cv_params <- expand.grid(max_depth_vals, min_child_weight)
names(cv_params) <- c("max_depth", "min_child_weight")

# results vector
auc_vec <- error_vec <- rep(NA, nrow(cv_params)) 

# for loop that tests each combination of max depth and min child weight
for(i in 1:nrow(cv_params)){
  set.seed(12345)
  boost_md_mcw_tune <- xgb.cv(data = dtrain,
              nfold = 5,
              eta = 0.1,
              max.depth = cv_params$max_depth[i],
              min_child_weight = cv_params$min_child_weight[i],
              nrounds = 100,
              early_stopping_rounds = 20,
              verbose = 1,
              nthread = 1,
              print_every_n = 20,
              objective = "binary:logistic",
              eval_metric = "auc",
              eval_metric = "error")
  
  # fill in NA grid with values of auc and error
  auc_vec[i] <- boost_md_mcw_tune$evaluation_log$test_auc_mean[boost_md_mcw_tune$best_ntreelimit]
  error_vec[i] <- boost_md_mcw_tune$evaluation_log$test_error_mean[boost_md_mcw_tune$best_ntreelimit]
}
```

Graph Heatmaps for best Max Depth and Min Child Weight Combinations by Error and AUC
```{r}
# data for parameter combos, auc, and error
res_db <- cbind.data.frame(cv_params, auc_vec, error_vec)
names(res_db)[3:4] <- c("auc", "error") 

# convert to factor for plotting
res_db$max_depth <- as.factor(res_db$max_depth)
res_db$min_child_weight <- as.factor(res_db$min_child_weight)

# heatmap for best combo by AUC
auc_plt_boost_md_mcw <- ggplot(res_db, aes(y = max_depth, x = min_child_weight, fill = auc)) +
  geom_tile() +
  theme_bw() +
  scale_fill_gradient2(low = "blue",
    mid = "white",
    high = "red",
    midpoint =mean(res_db$auc),
    space = "Lab", 
    na.value ="grey",
    guide = "colourbar",
    aesthetics = "fill") +
  labs(x = "Minimum Child Weight", y = "Max Depth", fill = "AUC")
auc_plt_boost_md_mcw

# heatmap for best combo by error
error_plt_boost_md_mcw <- ggplot(res_db, aes(y = max_depth, x = min_child_weight, fill = error)) +
  geom_tile() +
  theme_bw() +
  scale_fill_gradient2(low = "blue",
    mid = "white",
    high = "red",
    midpoint =mean(res_db$error),
    space = "Lab", 
    na.value ="grey",
    guide = "colourbar",
    aesthetics = "fill") +
  labs(x = "Minimum Child Weight", y = "Max Depth", fill = "Error")
error_plt_boost_md_mcw
```

View Results of Max Dept and Min Child Weight Combinations
```{r}
# print results
res_db
# we choose the max depth as 5 and the minimum child weight as 75
```

Tune for Gamma Value Hyperparameter
```{r}
# create vector of possible gamma values
gamma_vals <- c(0, 0.05, 0.1, 0.15, 0.2)

# set seed and create empty initialized vectors for results
set.seed(12345)
auc_vec <- error_vec <- rep(NA, length(gamma_vals))

# create for loop testing each gamma value for each iteration
for(i in 1:length(gamma_vals)){
  bst_tune_gamma <- xgb.cv(data = dtrain,
              nfold = 5,
              eta = 0.1,
              max.depth = 5,
              min_child_weight = 75,
              gamma = gamma_vals[i],
              nrounds = 100,
              early_stopping_rounds = 20,
              verbose = 1,
              nthread = 1,
              print_every_n = 20,
              objective = "binary:logistic",
              eval_metric = "auc",
              eval_metric = "error")
  
  # store results of each iteration in the vectors
  auc_vec[i] <- bst_tune_gamma$evaluation_log$test_auc_mean[bst_tune_gamma$best_ntreelimit]
  error_vec[i] <- bst_tune_gamma$evaluation_log$test_error_mean[bst_tune_gamma$best_ntreelimit]
  
}
```

Identify the Best Gamma Value
```{r}
# view auc and error by gamma value tested
cbind.data.frame(gamma_vals, auc_vec, error_vec)
# we choose 0.15 as our best gamma value
```

Run to Re-Calibrate the Number of Trees
```{r}
# set seed and run
set.seed(12345)
boost_recalibrate_trees <- xgb.cv(data = dtrain,
              nfold = 5,
              eta = 0.1,
              max.depth = 5,
              min_child_weight = 75,
              gamma = 0.15,
              nrounds = 1000,
              early_stopping_rounds = 50,
              verbose = 1,
              nthread = 1,
              print_every_n = 20,
              objective = "binary:logistic",
              eval_metric = "auc",
              eval_metric = "error")
# we see that our rounds are still good, maxing around 55
```

Tune Subsample and Colsample Hyperparameters
```{r}
# create vectors of possible subsample and colsample vectors for testing
subsample <- c(0.6, 0.7, 0.8, 0.9, 1)
colsample_by_tree <- c(0.6, 0.7, 0.8, 0.9, 1)

# establish grid for each combination
cv_params <- expand.grid(subsample, colsample_by_tree)
names(cv_params) <- c("subsample", "colsample_by_tree")

# create vectors to store results
auc_vec <- error_vec <- rep(NA, nrow(cv_params)) 

# loop through parameter values
for(i in 1:nrow(cv_params)){
  set.seed(12345)
  boost_tune_samp <- xgb.cv(data = dtrain,
              nfold = 5,
              eta = 0.1,
              max.depth = 5,
              min_child_weight = 75,
              gamma = 0.15,
              subsample = cv_params$subsample[i],
              colsample_bytree = cv_params$colsample_by_tree[i],
              nrounds = 150,
              early_stopping_rounds = 20,
              verbose = 1,
              nthread = 1,
              print_every_n = 20,
              objective = "binary:logistic",
              eval_metric = "auc",
              eval_metric = "error")
  
  # store results in vectors
  auc_vec[i] <- boost_tune_samp$evaluation_log$test_auc_mean[boost_tune_samp$best_ntreelimit]
  error_vec[i] <- boost_tune_samp$evaluation_log$test_error_mean[boost_tune_samp$best_ntreelimit]
  
}
```

View Graphs to Find Best Subsample & Colsample Combination
```{r}
# gather parameters and auc/error
res_db <- cbind.data.frame(cv_params, auc_vec, error_vec)
names(res_db)[3:4] <- c("auc", "error") 

# convert tree number to factor for plotting
res_db$subsample <- as.factor(res_db$subsample)
res_db$colsample_by_tree <- as.factor(res_db$colsample_by_tree)

# graph auc for combinations
auc_plt_boost_samp <- ggplot(res_db, aes(y = colsample_by_tree, x = subsample, fill = auc)) +
  geom_tile() +
  theme_bw() +
  scale_fill_gradient2(low = "blue",
    mid = "white",
    high = "red",
    midpoint =mean(res_db$auc),
    space = "Lab", 
    na.value ="grey",
    guide = "colourbar",
    aesthetics = "fill") +
  labs(x = "Subsample", y = "Column Sample by Tree", fill = "AUC")
auc_plt_boost_samp

# graph error for combinations
error_plt_boost_samp <- ggplot(res_db, aes(y = colsample_by_tree, x = subsample, fill = error)) +
  geom_tile() +
  theme_bw() +
  scale_fill_gradient2(low = "blue",
    mid = "white",
    high = "red",
    midpoint =mean(res_db$error),
    space = "Lab", 
    na.value ="grey",
    guide = "colourbar",
    aesthetics = "fill") +
  labs(x = "Subsample", y = "Column Sample by Tree", fill = "Error")
error_plt_boost_samp
```

View Combinations in Table Form
```{r}
# view combinations
res_db
# we are choosing colsample of 0.8 and subsample of 0.6
```

Attempt Different Learning Rates
Testing ETA of 0.3
```{r}
set.seed(12345)
bst_mod_1 <- xgb.cv(data = dtrain,
              nfold = 5,
              eta = 0.3,
              max.depth = 5,
              min_child_weight = 75,
              gamma = 0.15,
              subsample = 0.8,
              colsample_bytree =  0.6,
              nrounds = 1000,
              early_stopping_rounds = 20,
              verbose = 1,
              nthread = 1,
              print_every_n = 20,
              objective = "binary:logistic",
              eval_metric = "auc",
              eval_metric = "error")
```

Testing ETA of 0.1
```{r}
set.seed(12345)
bst_mod_2 <- xgb.cv(data = dtrain,
              nfold = 5,
              eta = 0.1,
              max.depth = 5,
              min_child_weight = 75,
              gamma = 0.15,
              subsample = 0.8,
              colsample_bytree =  0.6,
              nrounds = 1000,
              early_stopping_rounds = 20,
              verbose = 1,
              nthread = 1,
              print_every_n = 20,
              objective = "binary:logistic",
              eval_metric = "auc",
              eval_metric = "error")
```

Testing ETA of 0.05
```{r}
set.seed(12345)
bst_mod_3 <- xgb.cv(data = dtrain,
              nfold = 5,
              eta = 0.05,
              max.depth = 5,
              min_child_weight = 75,
              gamma = 0.15,
              subsample = 0.8,
              colsample_bytree =  0.6,
              nrounds = 1000,
              early_stopping_rounds = 20,
              verbose = 1,
              nthread = 1,
              print_every_n = 20,
              objective = "binary:logistic",
              eval_metric = "auc",
              eval_metric = "error")
```

Testing ETA of 0.01
```{r}
set.seed(12345)
bst_mod_4 <- xgb.cv(data = dtrain,
              nfold = 5,
              eta = 0.01,
              max.depth = 5,
              min_child_weight = 75,
              gamma = 0.15,
              subsample = 0.8,
              colsample_bytree =  0.6,
              nrounds = 1000,
              early_stopping_rounds = 20,
              verbose = 1,
              nthread = 1,
              print_every_n = 20,
              objective = "binary:logistic",
              eval_metric = "auc",
              eval_metric = "error")
```

Testing ETA of 0.005
```{r}
set.seed(12345)
bst_mod_5 <- xgb.cv(data = dtrain,
              nfold = 5,
              eta = 0.005,
              max.depth = 5,
              min_child_weight = 75,
              gamma = 0.15,
              subsample = 0.8,
              colsample_bytree =  0.6,
              nrounds = 1000,
              early_stopping_rounds = 20,
              verbose = 1,
              nthread = 1,
              print_every_n = 20,
              objective = "binary:logistic",
              eval_metric = "auc",
              eval_metric = "error")
```

Extract Results for Each Error
```{r}
# extract results for model with eta = 0.3
pd1 <- cbind.data.frame(bst_mod_1$evaluation_log[,c("iter", "test_error_mean")], rep(0.3, nrow(bst_mod_1$evaluation_log)))
names(pd1)[3] <- "eta"

# extract results for model with eta = 0.1
pd2 <- cbind.data.frame(bst_mod_2$evaluation_log[,c("iter", "test_error_mean")], rep(0.1, nrow(bst_mod_2$evaluation_log)))
names(pd2)[3] <- "eta"

# extract results for model with eta = 0.05
pd3 <- cbind.data.frame(bst_mod_3$evaluation_log[,c("iter", "test_error_mean")], rep(0.05, nrow(bst_mod_3$evaluation_log)))
names(pd3)[3] <- "eta"

# extract results for model with eta = 0.01
pd4 <- cbind.data.frame(bst_mod_4$evaluation_log[,c("iter", "test_error_mean")], rep(0.01, nrow(bst_mod_4$evaluation_log)))
names(pd4)[3] <- "eta"

# extract results for model with eta = 0.005
pd5 <- cbind.data.frame(bst_mod_5$evaluation_log[,c("iter", "test_error_mean")], rep(0.005, nrow(bst_mod_5$evaluation_log)))
names(pd5)[3] <- "eta"

# join datasets
plot_data <- rbind.data.frame(pd1, pd2, pd3, pd4, pd5)

# convert ETA to factor
plot_data$eta <- as.factor(plot_data$eta)

# plot points
plt_gamma_pts <- ggplot(plot_data, aes(x = iter, y = test_error_mean, color = eta))+
  geom_point(alpha = 0.5) +
  theme_bw() + # Set theme
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank()) + 
  labs(x = "Number of Trees", title = "Error Rate v Number of Trees",
       y = "Error Rate", color = "Learning \n Rate")
plt_gamma_pts

# plot lines
plt_gamma_lines <- ggplot(plot_data, aes(x = iter, y = test_error_mean, color = eta))+
  geom_smooth(alpha = 0.5) +
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank()) + 
  labs(x = "Number of Trees", title = "Error Rate v Number of Trees",
       y = "Error Rate", color = "Learning \n Rate")
plt_gamma_lines
```

XGBoost Final Model with Tuned Hyperparameters
```{r}
# set final xgboost model with all of the tuned hyperparameters
set.seed(12345)
boost_final <- xgboost(data = dtrain,
              eta = 0.1,
              max.depth =  5,
              min_child_weight = 75,
              gamma = 0.15,
              subsample =  0.8,
              colsample_bytree = 0.6,
              nrounds = 150,
              early_stopping_rounds = 20,
              verbose = 1,
              nthread = 1,
              print_every_n = 20,
              objective = "binary:logistic",
              eval_metric = "auc",
              eval_metric = "error")
```

Predictions for XGBoost Final Model
```{r}
# create predictions for xgboost model
boost_preds <- predict(boost_final, dtest)
pred_dat <- cbind.data.frame(boost_preds , encoded_test_data$HeartDisease)

# convert predictions to classes, using optimal cut-off (tested)
boost_pred_class <- rep(0, length(boost_preds))
boost_pred_class[boost_preds >= 0.08] <- 1

# create table and confusion matrix
t <- table(boost_pred_class, encoded_test_data$HeartDisease)
confusionMatrix(t, positive = "1")
```

Balanced XGBoost Model
```{r}
# determine the weight parameter
summary(as.factor(encoded_train_data$HeartDisease))
one_weight <- 22570/174250
```

Create XGBoost Weighted Model
```{r}
# set seed and make balanced model
set.seed(12345)
boost_balanced <- xgboost(data = dtrain,
              eta = 0.1,
              max.depth =  5,
              min_child_weight = 75,
              gamma = 0.15,
              subsample =  0.8,
              colsample_bytree = 0.6,
              nrounds = 150,
              early_stopping_rounds = 20,
              verbose = 1,
              nthread = 1,
              print_every_n = 20,
              scale_pos_weight = one_weight,
              objective = "binary:logistic",
              eval_metric = "auc",
              eval_metric = "error")
```

Predictions for Final Balanced XGBoost Model
```{r}
# create predictions for XGBoost model
boost_preds_bal <- predict(boost_balanced, dtest)
pred_dat <- cbind.data.frame(boost_preds_bal , encoded_test_data$HeartDisease)

# convert predictions to classes, using optimal cut-off
boost_pred_class <- rep(0, length(boost_preds_bal))
# cutoff has to be around .46 or they all get classified as one class
boost_pred_class[boost_preds_bal >= 0.4518] <- 1

# create table and confusion matrix
t <- table(boost_pred_class, encoded_test_data$HeartDisease)
confusionMatrix(t, positive = "1")
```

Extract Feature Importance
```{r}
# extract importance
imp_mat <- xgb.importance(model = boost_balanced)

# plot importance (top 10 variables)
xgb.plot.importance(imp_mat, top_n = 10)
```

Functions for XGBoost Explainer and Functions
```{r}
getTreeBreakdown = function(tree, col_names){

  ####accepts a tree (data table), and column names
  ####outputs a data table, of the impact of each variable + intercept, for each leaf

  tree_breakdown <- vector("list", length(col_names)  + 2)
  names(tree_breakdown) = c(col_names,'intercept','leaf')

  leaves = tree[leaf==T, Node]

  for (leaf in leaves){

    leaf_breakdown = getLeafBreakdown(tree,leaf,col_names)
    leaf_breakdown$leaf = leaf
    tree_breakdown = rbindlist(append(list(tree_breakdown),list(leaf_breakdown)))
  }

  return (tree_breakdown)
}
```
```{r}
buildExplainerFromTreeList = function(tree_list,col_names){
 
  ####accepts a list of trees and column names
  ####outputs a data table, of the impact of each variable + intercept, for each leaf

  tree_list_breakdown <- vector("list", length(col_names)  + 3)
  names(tree_list_breakdown) = c(col_names,'intercept', 'leaf','tree')

  num_trees = length(tree_list)
 
  cat('\n\nGetting breakdown for each leaf of each tree...\n')
  pb <- txtProgressBar(style=3)
 
  for (x in 1:num_trees){
    tree = tree_list[[x]]
    tree_breakdown = getTreeBreakdown(tree, col_names)
    tree_breakdown$tree = x - 1
    tree_list_breakdown = rbindlist(append(list(tree_list_breakdown),list(tree_breakdown)))
    setTxtProgressBar(pb, x / num_trees)
  }
 
  return (tree_list_breakdown)
 
}
```
```{r}
getStatsForTrees = function(trees, nodes.train, type = "binary", base_score = 0.5){
  #Accepts data table of tree (the output of xgb.model.dt.tree)
  #Returns a list of tree, with the stats filled in
 
  tree_list = copy(trees)
  tree_list[,leaf := Feature == 'Leaf']
  tree_list[,H:=Cover]
 
  non.leaves = which(tree_list[,leaf]==F)

 
  # The default cover (H) seems to lose precision so this loop recalculates it for each node of each tree
  cat('\n\nRecalculating the cover for each non-leaf... \n')
  pb <- txtProgressBar(style=3)
  j = 0
  for (i in rev(non.leaves)){
    left = tree_list[i,Yes]
    right = tree_list[i,No]
    tree_list[i,H:=tree_list[ID==left,H] + tree_list[ID==right,H]]
    j=j+1
    setTxtProgressBar(pb, j / length(non.leaves))
  }
 

  if (type == 'regression'){
    base_weight = base_score
  } else{
    base_weight = log(base_score / (1-base_score))
  }
 
  tree_list[leaf==T,weight:=base_weight + Quality]
 
  tree_list[,previous_weight:=base_weight]
  tree_list[1,previous_weight:=0]
 
  tree_list[leaf==T,G:=-weight*H]
 
  tree_list = split(tree_list,as.factor(tree_list$Tree))
  num_tree_list = length(tree_list)
  treenums =  as.character(0:(num_tree_list-1))
  t = 0
  cat('\n\nFinding the stats for the xgboost trees...\n')
  pb <- txtProgressBar(style=3)
  for (tree in tree_list){
    t=t+1
    num_nodes = nrow(tree)
    non_leaf_rows = rev(which(tree[,leaf]==F))
    for (r in non_leaf_rows){
        left = tree[r,Yes]
        right = tree[r,No]
        leftG = tree[ID==left,G]
        rightG = tree[ID==right,G]
       
        tree[r,G:=leftG+rightG]
        w=tree[r,-G/H]
       
        tree[r,weight:=w]
        tree[ID==left,previous_weight:=w]
        tree[ID==right,previous_weight:=w]
    }
   
    tree[,uplift_weight:=weight-previous_weight]
    setTxtProgressBar(pb, t / num_tree_list)
  }
 
  return (tree_list)
}
```
```{r}
getLeafBreakdown = function(tree,leaf,col_names){
 
  ####accepts a tree, the leaf id to breakdown and column names
  ####outputs a list of the impact of each variable + intercept
 
  impacts = as.list(rep(0,length(col_names)))
  names(impacts) = col_names
 
  path = findPath(tree,leaf)
  reduced_tree = tree[Node %in% path,.(Feature,uplift_weight)]
 
  impacts$intercept=reduced_tree[1,uplift_weight]
  reduced_tree[,uplift_weight:=shift(uplift_weight,type='lead')]
 
  tmp = reduced_tree[,.(sum=sum(uplift_weight)),by=Feature]
  tmp = tmp[-nrow(tmp)]
  impacts[tmp[,Feature]]=tmp[,sum]
 
  return (impacts)
}
```
```{r}
getLeafBreakdown = function(tree,leaf,col_names){
 
  ####accepts a tree, the leaf id to breakdown and column names
  ####outputs a list of the impact of each variable + intercept
 
  impacts = as.list(rep(0,length(col_names)))
  names(impacts) = col_names
 
  path = findPath(tree,leaf)
  reduced_tree = tree[Node %in% path,.(Feature,uplift_weight)]
 
  impacts$intercept=reduced_tree[1,uplift_weight]
  reduced_tree[,uplift_weight:=shift(uplift_weight,type='lead')]
 
  tmp = reduced_tree[,.(sum=sum(uplift_weight)),by=Feature]
  tmp = tmp[-nrow(tmp)]
  impacts[tmp[,Feature]]=tmp[,sum]
 
  return (impacts)
}
```
```{r}
findPath = function(tree, currentnode, path = c()){
 
  #accepts a tree data table, and the node to reach
  #path is used in the recursive function - do not set this
 
  while(currentnode>0){
    path = c(path,currentnode)
    currentlabel = tree[Node==currentnode,ID]
    currentnode = c(tree[Yes==currentlabel,Node],tree[No==currentlabel,Node])
  }
  return (sort(c(path,0)))
 
}
```
```{r}
findLeaves = function(tree, currentnode){
 
  if (tree[currentnode,'Feature']=='Leaf'){
    leaves = currentnode
  }else{
    leftnode = tree[currentnode,Yes]
    rightnode = tree[currentnode,No]
    leaves = c(findLeaves(tree,'leftnode',with=FALSE),findLeaves(tree,'rightnode',with=FALSE))
  }
 
  return (sort(leaves))
 
 
}
```
```{r}
buildExplainer = function(xgb.model,
                          trainingData,
                       
                          type = "binary", base_score = 0.5, trees_idx = NULL){

  col_names = colnames(trainingData)
  cat('\nCreating the trees of the xgboost model...')
  trees = xgb.model.dt.tree(col_names, model = xgb.model, trees = trees_idx)
  cat('\nGetting the leaf nodes for the training set observations...')
  nodes.train = predict(xgb.model,trainingData,predleaf =TRUE)

  cat('\nBuilding the Explainer...')
  cat('\nSTEP 1 of 2')
  tree_list = getStatsForTrees(trees, nodes.train, type = type, base_score = base_score)
  cat('\n\nSTEP 2 of 2')
  explainer = buildExplainerFromTreeList(tree_list,col_names)

  cat('\n\nDONE!\n\n')

  return (explainer)
}
```

Create and Call Explainer
```{r}
explainer = buildExplainer(boost_final, dtrain, type="binary", base_score = 0.08, trees_idx = NULL)
```

Breakdown Predictions
```{r}
pred.breakdown = explainPredictions(boost_final, explainer, dtest)
```

Call the ShowWaterfall Command for a Random Instance
```{r}
showWaterfall(boost_final, explainer, dtest, as.matrix(encoded_test_data[, 1:96]), 5643, type = "binary", threshold = 0.08)
```


